{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aiden\\AppData\\Local\\anaconda3\\envs\\hugging_face\\Lib\\importlib\\__init__.py:90: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aiden\\AppData\\Local\\anaconda3\\envs\\hugging_face\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"hf://datasets/yunfan-y/trump-qa/data/train-00000-of-00001.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rows where the column output or input length is more than 150\n",
    "df = df[df['output'].str.len() <= 150]\n",
    "df = df[df['input'].str.len() <= 150]\n",
    "\n",
    "# ask a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask a question\n",
    "messages = [\n",
    "    SystemMessage(content=\"Your are an AI model that generates questions for a dialogue with Donald Trump. You will be the person asking the questions and the given text is the answer by Donald Trump. The question answer pair will later be used to fine-tune an AI model so that this model impersonates Donald Trump. You only generate one question. You do not generate any other text besides the question.\"),\n",
    "    HumanMessage(content=\"{text}\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 27/27 [00:00<00:00, 1149.25ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "c:\\Users\\Aiden\\AppData\\Local\\anaconda3\\envs\\hugging_face\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Aiden\\.cache\\huggingface\\hub\\datasets--yunfan-y--trump-qa. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/yunfan-y/trump-qa/commit/2147ae97e1e801d4083e4b7022ed449cb027e6ff', commit_message='Upload dataset', commit_description='', oid='2147ae97e1e801d4083e4b7022ed449cb027e6ff', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to huggingface dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset.push_to_hub(\"yunfan-y/trump-qa\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33596/33596 [3:25:30<00:00,  2.72it/s]  \n"
     ]
    }
   ],
   "source": [
    "# write a for loop to generate questions for each text in the dataframe\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    messages[1].content = row['text']\n",
    "    question = parser.invoke(model.invoke(messages))\n",
    "    df.at[index, 'input'] = question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column text to output\n",
    "df.rename(columns={'text': 'output'}, inplace=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugging_face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
