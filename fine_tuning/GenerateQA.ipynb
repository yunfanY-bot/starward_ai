{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aiden\\AppData\\Local\\anaconda3\\envs\\hugging_face\\Lib\\importlib\\__init__.py:90: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n",
      "c:\\Users\\Aiden\\AppData\\Local\\anaconda3\\envs\\hugging_face\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "model = ChatOllama(\n",
    "    model=\"gemma2:9b\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"hf://datasets/yunfan-y/trump-tweets-cleaned/data/train-00000-of-00001.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask a question\n",
    "messages = [\n",
    "    SystemMessage(content=\"Your are an AI model that generates questions for a dialogue with Donald Trump. You will be the person asking the questions and the given text is the answer by Donald Trump. The question answer pair will later be used to fine-tune an AI model so that this model impersonates Donald Trump. You only generate one question. You do not generate any other text besides the question.\"),\n",
    "    HumanMessage(content=\"{text}\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 34/34 [00:00<00:00, 1140.55ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/yunfan-y/trump-qa/commit/1e5eaf3aafe8d83693170b4d0773596c642a2ca6', commit_message='Upload dataset', commit_description='', oid='1e5eaf3aafe8d83693170b4d0773596c642a2ca6', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to huggingface dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset.push_to_hub(\"yunfan-y/trump-qa\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33596/33596 [3:25:30<00:00,  2.72it/s]  \n"
     ]
    }
   ],
   "source": [
    "# write a for loop to generate questions for each text in the dataframe\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    messages[1].content = row['text']\n",
    "    question = parser.invoke(model.invoke(messages))\n",
    "    df.at[index, 'input'] = question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column text to output\n",
    "df.rename(columns={'text': 'output'}, inplace=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugging_face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
